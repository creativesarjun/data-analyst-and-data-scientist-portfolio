{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9cc808",
   "metadata": {},
   "source": [
    "# Deep learning with Keras on Iris dataset \n",
    "\n",
    "In this practice project we will build a deep learning model to predict the type of flower with the popular Iris dataset. We will do this using the Keras library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7141cfab",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "17aae7a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\creat\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\creat\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (22.10.26)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: sklearn in c:\\users\\creat\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\creat\\anaconda3\\lib\\site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.20.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\creat\\anaconda3\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\creat\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Install related libraries for the project. \n",
    "\n",
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fabf059",
   "metadata": {},
   "source": [
    "## Prepare Input Data for Deep Learning\n",
    "\n",
    "The input data should be preprocessed and prepared for deep learning before it can be used to train the models. We will perform the following steps for preparing data:\n",
    "\n",
    "1. Load data into a pandas dataframe\n",
    "2. Convert the dataframe to a numpy array\n",
    "3. Separate the feature and target variables \n",
    "4. Scale the feature dataset\n",
    "5. Use one-hot-encoding for the target variable\n",
    "6. Split into training and test datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49a1bc",
   "metadata": {},
   "source": [
    "### 1. Load data into a pandas dataframe\n",
    "\n",
    "We first load the iris.csv file in into a pandas dataframe. We then print the contents of the dataframe to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6db4bd81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Data :\n",
      "------------------------------------\n",
      "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "#Load Data and review content\n",
    "iris_data = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "print(\"\\nLoaded Data :\\n------------------------------------\")\n",
    "print(iris_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469ebac2",
   "metadata": {},
   "source": [
    "The target variable 'Species' is a text field. It needs to be converted to a numeric representation for deep learning. For this, we use a LabelEncoder model based on the species column, and then update the species column with the corresponding encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3cae010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a Label encoder to convert String to numeric values \n",
    "#for the target variable\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "iris_data['Species'] = label_encoder.fit_transform(\n",
    "                                iris_data['Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483075e6",
   "metadata": {},
   "source": [
    " ### 2. Convert the dataframe to a numpy array\n",
    " \n",
    " Now, we convert the dataframe into a NumPy array, which is the preferred input format for Keras deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6f50fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input to numpy array\n",
    "np_iris = iris_data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba348e",
   "metadata": {},
   "source": [
    "### 3. Separate the feature and target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef267bdf",
   "metadata": {},
   "source": [
    "We separate the feature and target variables into different variables, namely X_data and Y_data. X_data has four columns and Y_data has one. We print the feature variables and target variable to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "195f9619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features before scaling :\n",
      "------------------------------------\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "\n",
      "Target before scaling :\n",
      "------------------------------------\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Separate feature and target variables\n",
    "X_data = np_iris[:,0:4]\n",
    "Y_data=np_iris[:,4]\n",
    "\n",
    "print(\"\\nFeatures before scaling :\\n------------------------------------\")\n",
    "print(X_data[:5,:])\n",
    "print(\"\\nTarget before scaling :\\n------------------------------------\")\n",
    "print(Y_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2357f4",
   "metadata": {},
   "source": [
    "### 4. Scale the feature dataset\n",
    "\n",
    "Since the feature variables are numeric and each column may be on a different scale, we need to standardize the scaling. For this, we create a scaler model on the data in X_data. Then we transform the data in X_data using this model. We will print the features after scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c57b9cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features after scaling :\n",
      "------------------------------------\n",
      "[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
      " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
      " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]\n",
      " [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]\n",
      " [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]\n"
     ]
    }
   ],
   "source": [
    "#Create a scaler model that is fit on the input data.\n",
    "scaler = StandardScaler().fit(X_data)\n",
    "\n",
    "#Scale the numeric feature variables\n",
    "X_data = scaler.transform(X_data)\n",
    "\n",
    "print(\"\\nFeatures after scaling :\\n------------------------------------\")\n",
    "print(X_data[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca2fc3",
   "metadata": {},
   "source": [
    "### 5. Use one-hot-encoding for the target variable\n",
    "\n",
    "Since the target variables is multi-class, we will use one hot encoding to create three columns with each column representing a species. We will print the features after one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2ce74f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target after one-hot-encoding :\n",
      "------------------------------------\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Convert target variable as a one-hot-encoding array\n",
    "Y_data = tf.keras.utils.to_categorical(Y_data,3)\n",
    "\n",
    "print(\"\\nTarget after one-hot-encoding :\\n------------------------------------\")\n",
    "print(Y_data[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9790ba1",
   "metadata": {},
   "source": [
    "### 6. Split into training and test datasets\n",
    "\n",
    "Finally, we need to split the data set into training and test data sets. 10% of the data set is allocated for testing. We print the dimension of these data sets. Note: we are not splitting for validation as Keras has a feature to create a validation data set from the training data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b72ce8f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Test Dimensions:\n",
      "------------------------------------\n",
      "(135, 4) (135, 3) (15, 4) (15, 3)\n"
     ]
    }
   ],
   "source": [
    "#Split training and test data\n",
    "X_train,X_test,Y_train,Y_test = train_test_split( X_data, Y_data, test_size=0.10)\n",
    "\n",
    "print(\"\\nTrain Test Dimensions:\\n------------------------------------\")\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a75b03",
   "metadata": {},
   "source": [
    "Now pre-processing is complete and we can see the output. We loaded the data in its raw form. We then converted the features into numeric values of the same scale. The target variable now is one hot encoded with three columns. And finally, we split training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5fad2",
   "metadata": {},
   "source": [
    "## Creating a Model\n",
    "\n",
    "Creating a model in Keras requires defining the following, the architecture and hyperparameters for the neural network. Once the model is defined we can train and retrain the model any number of times. \n",
    "\n",
    "1. Number of hidden layers\n",
    "2. Number of nodes in each layer\n",
    "3. Activation functions\n",
    "4. Loss Function & Accuracy measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39513ef",
   "metadata": {},
   "source": [
    "Let's define the number of classes in the target variable. We have used one-hot encoding on the target variables before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d4a0be90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Number of classes in the target variable\n",
    "NB_CLASSES=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec601a7",
   "metadata": {},
   "source": [
    "We now proceed to create a sequential model in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "292b4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sequencial model in Keras\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8702d2",
   "metadata": {},
   "source": [
    "We now start adding layers to the model. We add the first hidden layer of 128 nodes. This is a number we can experiment with as we improve the model. Then, we define the input shape. Since we know that we have four input variables, we define the same here. We provide a logical name 'Hidden-Layer-1' for the layer and this is helpful in printing information later. We will use rectified linear unit activation for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "89ed3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the first hidden layer\n",
    "model.add(keras.layers.Dense(128,                    #Number of nodes\n",
    "                             input_shape=(4,),       #Number of input variables\n",
    "                              name='Hidden-Layer-1', #Logical name\n",
    "                              activation='relu'))    #activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5f3cb",
   "metadata": {},
   "source": [
    "We add another hidden layer, Hidden-Layer-2 which will again have 128 nodes, and activation of relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f17ee3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a second hidden layer\n",
    "model.add(keras.layers.Dense(128,\n",
    "                              name='Hidden-Layer-2',\n",
    "                              activation='relu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508cb6ba",
   "metadata": {},
   "source": [
    "Finally, we add the output layer. Here, the number of nodes will be equal to the number of classes in the target variable. We will use softmax activation to predict the probabilities of each class for the input provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "428fb300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add an output layer with softmax activation\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "                             name='Output-Layer',\n",
    "                             activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ccff4c",
   "metadata": {},
   "source": [
    "For loss computation, we will use categorical_crossentropy, since this is a multi-class classification model. We will also use accuracy as the metric to measure loss. We will assume default values for the other parameters to compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3fedf808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model with loss & metrics\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3867a",
   "metadata": {},
   "source": [
    "Then, we will compile the model.We see the model summary being printed here. It shows each layer and the shape of the output. It also shows the total number of parameters in the model, which are the weights and biases across the two hidden and one output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3813461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden-Layer-1 (Dense)      (None, 128)               640       \n",
      "                                                                 \n",
      " Hidden-Layer-2 (Dense)      (None, 128)               16512     \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,539\n",
      "Trainable params: 17,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print the model meta-data\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6677e",
   "metadata": {},
   "source": [
    "## Training and evaluating the Model\n",
    "\n",
    "We have now prepared the input data and created a model. Let's now go ahead and train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a2337",
   "metadata": {},
   "source": [
    "We set the verbose to one, so Keras will print out details of progress during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "df250a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make it verbose so we can see the progress\n",
    "VERBOSE=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706568c",
   "metadata": {},
   "source": [
    "We then set the hyper parameters for training. These are of course set initially on intuition and then fine tuned on experimentation as we improve the model. We set the batch size to 16, which is in the two power n range. We set the number of epochs to 10. We will use a validation split of 20%. This means that 20% of the training data will be used by Keras for validation after each epoch. Though the recommended percentage of validation is 10, we are using more samples since the total sample size is 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "810d4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Hyper Parameters for training\n",
    "\n",
    "#Set Batch size\n",
    "BATCH_SIZE=16\n",
    "#Set number of epochs\n",
    "EPOCHS=10\n",
    "#Set validation split. 20% of the training data will be used for validation\n",
    "#after each epoch\n",
    "VALIDATION_SPLIT=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d36a851",
   "metadata": {},
   "source": [
    "Training a model is straightforward in Keras with a single function call. The model.fit method is used to train and also capture details about the training. The first parameter is the input feature variable followed by the target variable. Then we set values for batch size, epochs, verbose and validation split. This function will initialize the weights and biases, but from gradient descent and store the final weights and biases in the model. It also can expose the history of training as a return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "80395709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Progress:\n",
      "------------------------------------\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.8697 - accuracy: 0.6667 - val_loss: 0.6669 - val_accuracy: 0.7778\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5534 - accuracy: 0.8241 - val_loss: 0.5070 - val_accuracy: 0.8148\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.8519 - val_loss: 0.4289 - val_accuracy: 0.8148\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3628 - accuracy: 0.8519 - val_loss: 0.3715 - val_accuracy: 0.8519\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3189 - accuracy: 0.8704 - val_loss: 0.3349 - val_accuracy: 0.8148\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2800 - accuracy: 0.8796 - val_loss: 0.3043 - val_accuracy: 0.8148\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2559 - accuracy: 0.8981 - val_loss: 0.2904 - val_accuracy: 0.8148\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2258 - accuracy: 0.9074 - val_loss: 0.2702 - val_accuracy: 0.8148\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2027 - accuracy: 0.9259 - val_loss: 0.2534 - val_accuracy: 0.8148\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1875 - accuracy: 0.9352 - val_loss: 0.2443 - val_accuracy: 0.8148\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Progress:\\n------------------------------------\")\n",
    "\n",
    "#Fit the model. This will perform the entire training cycle, including\n",
    "#forward propagation, loss computation, backward propagation and gradient descent.\n",
    "#Execute for the specified batch sizes and epoch\n",
    "#Perform validation after each epoch \n",
    "history=model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1220d0",
   "metadata": {},
   "source": [
    "We use this history and plot the accuracy of in sample predictions against the epochs. Finally, we will evaluate the model against the test data set and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1a26aa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy during Training :\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation against Test Dataset :\n",
      "------------------------------------\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2798 - accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27984967827796936, 0.9333333373069763]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nAccuracy during Training :\\n------------------------------------\")\n",
    "\n",
    "#Plot accuracy of the model after each epoch.\n",
    "pd.DataFrame(history.history)[\"accuracy\"].plot(figsize=(8, 5))\n",
    "plt.title(\"Accuracy improvements with Epoch\")\n",
    "plt.show()\n",
    "\n",
    "#Evaluate the model against the test dataset and print results\n",
    "print(\"\\nEvaluation against Test Dataset :\\n------------------------------------\")\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2eaf4c",
   "metadata": {},
   "source": [
    "We see the training progress printed after each epoch. It shows the total amount of time taken, and the last computed by the cost function. It also prints the accuracy of predictions against the in sample dataset. Additionally, it prints the loss and accuracy of predictions against the validation data set. From the plot, we can observe that as the number of epochs increases, the accuracy also increases progressively and reaches about 90%. If accuracy at this point is not acceptable, we can increase the number of epochs and retry. The evaluation against a test dataset also shows an accuracy of 93%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55efdff7",
   "metadata": {},
   "source": [
    "## Saving and Loading Models\n",
    "\n",
    "The training and inference environments are usually separate. Models need to be saved after they are validated. They are then loaded into the inference environments for actual prediction.\n",
    "\n",
    "In order to save a model, we use the save method to save the model architecture, parameters and other information to disk. Here we saved the contents to 'iris_save', which is a directory under which the model elements are saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7434d7cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Hidden-Layer-1_input with unsupported characters which will be renamed to hidden_layer_1_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: iris_save\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: iris_save\\assets\n"
     ]
    }
   ],
   "source": [
    "#Saving a model\n",
    "    \n",
    "model.save(\"iris_save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d197a8a",
   "metadata": {},
   "source": [
    "We can load the model back with the load model function. Once loaded, we can print the summary and check the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "548e6d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden-Layer-1 (Dense)      (None, 128)               640       \n",
      "                                                                 \n",
      " Hidden-Layer-2 (Dense)      (None, 128)               16512     \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,539\n",
      "Trainable params: 17,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Loading a Model \n",
    "loaded_model = keras.models.load_model(\"iris_save\")\n",
    "\n",
    "#Print Model Summary\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e51e0ce",
   "metadata": {},
   "source": [
    "We can also explore the contents of Iris save, the model is saved here in binary format with all the format and metadata under the root directory of the files. To copy the model, we need to copy the entire root directory and move it to the destination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc6fb5",
   "metadata": {},
   "source": [
    "## Predictions with Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e991e",
   "metadata": {},
   "source": [
    "Having trained a deep learning model for Iris, let's do some predictions with new data. We start with a prediction input of four feature variables namely; sepal length, sepal width, petal length and Petal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "58037d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raw prediction data\n",
    "prediction_input = [[6.6, 3. , 4.4, 1.4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2756ffce",
   "metadata": {},
   "source": [
    "The featured variables need to go through the same set of pre-processing that was done during training. We use the same scaler model we built during training to scale the prediction feature variables too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "dc76d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale prediction data with the same scaling model\n",
    "scaled_input = scaler.transform(prediction_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6c3b7",
   "metadata": {},
   "source": [
    "Then we use the predict method on the model to predict for the scaled input. The raw prediction results are captured and printed. The result is a list of probabilities of the various classes, as it applies for this input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a8397de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "Raw Prediction Output (Probabilities) : [[0.03153917 0.6737354  0.29472545]]\n"
     ]
    }
   ],
   "source": [
    "#Get raw prediction probabilities\n",
    "raw_prediction = model.predict(scaled_input)\n",
    "print(\"Raw Prediction Output (Probabilities) :\" , raw_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a9d66",
   "metadata": {},
   "source": [
    "We then use the argmax function to get the index of the highest probability. Then we use the same training label encoder to do the reverse transform and get the string for the species name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3a00fbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is  ['versicolor']\n"
     ]
    }
   ],
   "source": [
    "#Find prediction\n",
    "prediction = np.argmax(raw_prediction)\n",
    "print(\"Prediction is \", label_encoder.inverse_transform([prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f37fb8",
   "metadata": {},
   "source": [
    "For the raw output, we see the probabilities for the three classes namely; setosa, versicolor and virginica. The sum of the three probabilities will be one. From the list, versicolor has the highest probability of 65%. Then the inverse transform function will extract the corresponding name which is versicolor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
